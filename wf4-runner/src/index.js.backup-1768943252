import express from 'express';
import { exec as execCallback } from 'child_process';
import { promisify } from 'util';
import fs from 'fs/promises';
import path from 'path';

const exec = promisify(execCallback);
const app = express();
app.use(express.json());

const PORT = process.env.PORT || 8787;
const GITHUB_TOKEN = process.env.GITHUB_TOKEN;

// In-memory build state
const builds = new Map();

// ========================================
// HEALTH CHECK
// ========================================
app.get('/health', (req, res) => {
  res.json({ ok: true, timestamp: new Date().toISOString() });
});

// ========================================
// GET BUILD STATUS
// ========================================
app.get('/v1/status', (req, res) => {
  const { buildId } = req.query;

  if (!buildId) {
    return res.status(400).json({ error: 'buildId required' });
  }

  const build = builds.get(buildId);

  if (!build) {
    return res.status(404).json({
      status: 'NOT_FOUND',
      buildId
    });
  }

  res.json({
    status: build.status,
    frontendUrl: build.frontendUrl,
    backendUrl: build.backendUrl,
    errorReason: build.errorReason,
    logTail: build.logs.slice(-500)
  });
});

// ========================================
// GET BUILD RESULT
// ========================================
app.get('/v1/result', (req, res) => {
  const { buildId } = req.query;

  if (!buildId) {
    return res.status(400).json({ error: 'buildId required' });
  }

  const build = builds.get(buildId);

  if (!build) {
    return res.status(404).json({ error: 'Build not found' });
  }

  res.json({
    status: build.status,
    frontendUrl: build.frontendUrl,
    backendUrl: build.backendUrl,
    errorReason: build.errorReason,
    logs: build.logs,
    branch: build.branch
  });
});

// ========================================
// PERSIST RESULT
// ========================================
app.post('/v1/persistResult', (req, res) => {
  const { buildId, result } = req.body;

  if (!buildId || !result) {
    return res.status(400).json({ error: 'buildId and result required' });
  }

  const build = builds.get(buildId);

  if (build) {
    Object.assign(build, result);
    console.log(`âœ… Persisted result for ${buildId}`);
  }

  res.json({ ok: true });
});

// ========================================
// START BUILD
// ========================================
app.post('/v1/build', async (req, res) => {
  const { buildId, repoOwner, repoName, branch, mode } = req.body;

  if (!buildId || !repoOwner || !repoName || !branch) {
    return res.status(400).json({
      error: 'Missing required fields',
      required: ['buildId', 'repoOwner', 'repoName', 'branch']
    });
  }

  console.log(`\n${'='.repeat(60)}`);
  console.log(`ğŸš€ BUILD STARTED: ${buildId}`);
  console.log(`   Repo: ${repoOwner}/${repoName}`);
  console.log(`   Branch: ${branch}`);
  console.log(`   Mode: ${mode}`);
  console.log(`${'='.repeat(60)}\n`);

  // Initialize build state
  builds.set(buildId, {
    status: 'RUNNING',
    frontendUrl: null,
    backendUrl: null,
    errorReason: null,
    logs: '',
    startedAt: Date.now(),
    branch: branch,
    repoOwner: repoOwner,
    repoName: repoName
  });

  // Start async build
  runBuild(buildId, repoOwner, repoName, branch).catch(err => {
    console.error(`âŒ Build ${buildId} failed:`, err);
    const build = builds.get(buildId);
    if (build) {
      build.status = 'FAIL';
      build.errorReason = err.message;
      build.logs += `\n\nFATAL ERROR: ${err.message}\n${err.stack}`;
    }
  });

  res.json({ ok: true, buildId, status: 'RUNNING' });
});

// ========================================
// BUILD RUNNER (Async) - ENHANCED
// ========================================
async function runBuild(buildId, repoOwner, repoName, branch) {
  const build = builds.get(buildId);

  const log = (msg) => {
    console.log(msg);
    build.logs += msg + '\n';
  };

  try {
    // Step 1: Clone repo
    log('ğŸ“¦ Step 1/10: Cloning repository...');
    const workDir = `/tmp/${buildId}`;
    const repoUrl = `https://${GITHUB_TOKEN}@github.com/${repoOwner}/${repoName}.git`;

    await exec(`rm -rf ${workDir}`);
    await exec(`git clone --branch ${branch} --depth 1 ${repoUrl} ${workDir}`);
    log(`âœ… Repository cloned to ${workDir}`);

    // Step 2: Apply automatic fixes
    log('ğŸ“¦ Step 2/10: Applying automatic fixes...');
    await applyAutomaticFixes(workDir, log);
    log('âœ… Automatic fixes applied');

    // Step 3: Commit and push fixes
    log('ğŸ“¦ Step 3/10: Committing fixes to GitHub...');
    await commitAndPushFixes(workDir, branch, log);
    log('âœ… Fixes pushed to GitHub');

    // Step 4: Check for docker-compose
    log('ğŸ“¦ Step 4/10: Checking docker-compose.yml...');
    try {
      await exec(`test -f ${workDir}/docker-compose.yml`);
      log('âœ… Found docker-compose.yml');
    } catch {
      throw new Error('docker-compose.yml not found in repository');
    }

    // Step 5: Install dependencies
    log('ğŸ“¦ Step 5/10: Installing dependencies...');
    await installDependencies(workDir, log);
    log('âœ… Dependencies installed');

    // Step 6: Stop existing containers
    log('ğŸ“¦ Step 6/10: Cleaning up old containers...');
    try {
      await exec(`cd ${workDir} && docker-compose -p ${buildId} down -v`, { timeout: 30000 });
      log('âœ… Old containers stopped');
    } catch (err) {
      log(`âš ï¸  No old containers: ${err.message}`);
    }

    // Step 7: Build containers
    log('ğŸ“¦ Step 7/10: Building Docker containers...');
    const { stdout: buildOutput, stderr: buildErrors } = await exec(
      `cd ${workDir} && docker-compose -p ${buildId} build --no-cache`,
      { timeout: 600000, maxBuffer: 10 * 1024 * 1024 }
    );
    log(buildOutput);
    if (buildErrors) log(`Build warnings: ${buildErrors}`);
    log('âœ… Containers built');

    // Step 8: Start containers
    log('ğŸ“¦ Step 8/10: Starting containers...');
    await exec(`cd ${workDir} && docker-compose -p ${buildId} up -d`);
    log('âœ… Containers started');

    // Step 9: Get ports & wait for startup
    log('ğŸ“¦ Step 9/10: Waiting for services to be ready...');
    await new Promise(resolve => setTimeout(resolve, 15000));

    const frontendPort = await getContainerPort(buildId, 'frontend', 80);
    const backendPort = await getContainerPort(buildId, 'backend', 3000);

    build.frontendUrl = `http://localhost:${frontendPort}`;
    build.backendUrl = `http://localhost:${backendPort}`;

    log(`âœ… Frontend: ${build.frontendUrl}`);
    log(`âœ… Backend: ${build.backendUrl}`);

    // Step 10: Health checks
    log('ğŸ“¦ Step 10/10: Running health checks...');
    await performHealthChecks(build, log);

    build.status = 'PASS';
    log('\n' + '='.repeat(60));
    log('ğŸ‰ BUILD COMPLETE!');
    log('='.repeat(60));
    log(`\nğŸ“± OPEN YOUR APP:`);
    log(`   Frontend: ${build.frontendUrl}`);
    log(`   Backend:  ${build.backendUrl}`);
    log(`   GitHub:   https://github.com/${repoOwner}/${repoName}/tree/${branch}`);
    log('\n' + '='.repeat(60) + '\n');

  } catch (err) {
    log(`\nâŒ BUILD FAILED: ${err.message}\n`);
    log(`Stack trace: ${err.stack}\n`);
    build.status = 'FAIL';
    build.errorReason = err.message;
    throw err;
  }
}

// ========================================
// AUTOMATIC FIXES
// ========================================
async function applyAutomaticFixes(workDir, log) {
  // Fix 1: Create frontend/public directory
  log('  ğŸ”§ Creating frontend/public directory...');
  await exec(`mkdir -p ${workDir}/frontend/public`);
  
  // Fix 2: Create vite.svg in public if missing
  const viteSvgPath = path.join(workDir, 'frontend/public/vite.svg');
  try {
    await fs.access(viteSvgPath);
  } catch {
    log('  ğŸ”§ Creating vite.svg...');
    const viteSvg = `<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 410 404">
  <defs>
    <linearGradient id="a" x1="6%" x2="89%" y1="7%" y2="90%">
      <stop offset="0%" stop-color="#41D1FF"/>
      <stop offset="100%" stop-color="#BD34FE"/>
    </linearGradient>
  </defs>
  <path fill="url(#a)" d="M369 352.5 170.6 7.2a23.5 23.5 0 0 0-41.2 0L-29 352.5a23.5 23.5 0 0 0 20.6 35l358.8-.3a23.5 23.5 0 0 0 20.6-34.7Z"/>
  <path fill="#41D1FF" d="M149.3 336.7c9.7 11.6 28.5 10.8 37 .1l94.9-119.6c9-11.3 2-28-11.6-28H207c-6 0-11.6-2.5-15.6-7a25 25 0 0 1-5.8-19.8l9.7-66c.6-4-4.7-6-7-2.5L81.8 245.3c-8 12.4-.8 29.2 12.4 29.2h42c6.3 0 12.3 2.7 16.4 7.3a26 26 0 0 1 6.2 21.2l-9.5 33.7Z"/>
</svg>`;
    await fs.writeFile(viteSvgPath, viteSvg, 'utf-8');
  }

  // Fix 3: Ensure package.json has required dependencies
  log('  ğŸ”§ Checking frontend package.json...');
  const frontendPkgPath = path.join(workDir, 'frontend/package.json');
  try {
    const pkgContent = await fs.readFile(frontendPkgPath, 'utf-8');
    const pkg = JSON.parse(pkgContent);
    
    let modified = false;
    const requiredDeps = {
      'clsx': '^2.1.0',
      'tailwind-merge': '^2.2.0',
      'class-variance-authority': '^0.7.0'
    };

    if (!pkg.dependencies) pkg.dependencies = {};
    
    for (const [dep, version] of Object.entries(requiredDeps)) {
      if (!pkg.dependencies[dep]) {
        log(`  ğŸ”§ Adding missing dependency: ${dep}`);
        pkg.dependencies[dep] = version;
        modified = true;
      }
    }

    if (modified) {
      await fs.writeFile(frontendPkgPath, JSON.stringify(pkg, null, 2), 'utf-8');
      log('  âœ… Updated frontend package.json');
    }
  } catch (err) {
    log(`  âš ï¸  Could not update package.json: ${err.message}`);
  }

  // Fix 4: Fix TypeScript path aliases
  log('  ğŸ”§ Checking TypeScript configuration...');
  const tsconfigPath = path.join(workDir, 'frontend/tsconfig.json');
  try {
    const tsconfigContent = await fs.readFile(tsconfigPath, 'utf-8');
    const tsconfig = JSON.parse(tsconfigContent);
    
    if (!tsconfig.compilerOptions) tsconfig.compilerOptions = {};
    if (!tsconfig.compilerOptions.paths) {
      log('  ğŸ”§ Adding TypeScript path aliases...');
      tsconfig.compilerOptions.baseUrl = '.';
      tsconfig.compilerOptions.paths = {
        '@/*': ['./src/*']
      };
      await fs.writeFile(tsconfigPath, JSON.stringify(tsconfig, null, 2), 'utf-8');
      log('  âœ… Updated tsconfig.json');
    }
  } catch (err) {
    log(`  âš ï¸  Could not update tsconfig.json: ${err.message}`);
  }

  // Fix 5: Create vite.config.ts if missing path alias
  log('  ğŸ”§ Checking Vite configuration...');
  const viteConfigPath = path.join(workDir, 'frontend/vite.config.ts');
  try {
    let viteConfig = await fs.readFile(viteConfigPath, 'utf-8');
    
    if (!viteConfig.includes('resolve:') || !viteConfig.includes('alias:')) {
      log('  ğŸ”§ Adding Vite path alias configuration...');
      
      // Add path import if not present
      if (!viteConfig.includes("import path from 'path'")) {
        viteConfig = "import path from 'path';\n" + viteConfig;
      }

      // Add resolve.alias if not present
      if (!viteConfig.includes('resolve:')) {
        viteConfig = viteConfig.replace(
          'export default defineConfig({',
          `export default defineConfig({
  resolve: {
    alias: {
      '@': path.resolve(__dirname, './src'),
    },
  },`
        );
        await fs.writeFile(viteConfigPath, viteConfig, 'utf-8');
        log('  âœ… Updated vite.config.ts');
      }
    }
  } catch (err) {
    log(`  âš ï¸  Could not update vite.config.ts: ${err.message}`);
  }

  // Fix 6: Ensure .env files exist
  log('  ğŸ”§ Checking environment files...');
  const envFiles = [
    { path: path.join(workDir, '.env'), template: 'NODE_ENV=production\nGITHUB_TOKEN=\n' },
    { path: path.join(workDir, 'backend/.env'), template: 'PORT=3000\nNODE_ENV=production\n' },
    { path: path.join(workDir, 'frontend/.env'), template: 'VITE_API_URL=http://localhost:3000\n' }
  ];

  for (const envFile of envFiles) {
    try {
      await fs.access(envFile.path);
    } catch {
      log(`  ğŸ”§ Creating ${envFile.path}...`);
      await fs.writeFile(envFile.path, envFile.template, 'utf-8');
    }
  }
}

// ========================================
// COMMIT AND PUSH FIXES
// ========================================
async function commitAndPushFixes(workDir, branch, log) {
  try {
    // Configure git
    await exec(`cd ${workDir} && git config user.email "ai-factory@localhost"`);
    await exec(`cd ${workDir} && git config user.name "AI Factory"`);

    // Check if there are changes
    const { stdout: statusOutput } = await exec(`cd ${workDir} && git status --porcelain`);
    
    if (statusOutput.trim().length > 0) {
      log('  ğŸ“ Changes detected, committing...');
      
      // Add all changes
      await exec(`cd ${workDir} && git add .`);
      
      // Commit
      const commitMsg = `[AI Factory] Auto-fix: Added missing dependencies and configurations`;
      await exec(`cd ${workDir} && git commit -m "${commitMsg}"`);
      
      // Push to branch
      await exec(`cd ${workDir} && git push origin ${branch}`);
      
      log('  âœ… Changes committed and pushed to GitHub');
    } else {
      log('  â„¹ï¸  No changes to commit');
    }
  } catch (err) {
    log(`  âš ï¸  Could not commit/push: ${err.message}`);
  }
}

// ========================================
// INSTALL DEPENDENCIES
// ========================================
async function installDependencies(workDir, log) {
  // Install frontend dependencies
  log('  ğŸ“¦ Installing frontend dependencies...');
  try {
    await exec(`cd ${workDir}/frontend && npm install`, { timeout: 300000 });
    log('  âœ… Frontend dependencies installed');
  } catch (err) {
    log(`  âš ï¸  Frontend npm install warning: ${err.message}`);
  }

  // Install backend dependencies
  log('  ğŸ“¦ Installing backend dependencies...');
  try {
    await exec(`cd ${workDir}/backend && npm install`, { timeout: 300000 });
    log('  âœ… Backend dependencies installed');
  } catch (err) {
    log(`  âš ï¸  Backend npm install warning: ${err.message}`);
  }

  // Install shared dependencies if exists
  const sharedPath = path.join(workDir, 'shared');
  try {
    await fs.access(sharedPath);
    log('  ğŸ“¦ Installing shared dependencies...');
    await exec(`cd ${workDir}/shared && npm install`, { timeout: 300000 });
    log('  âœ… Shared dependencies installed');
  } catch (err) {
    // Shared folder might not exist, that's okay
  }
}

// ========================================
// HEALTH CHECKS
// ========================================
async function performHealthChecks(build, log) {
  const maxRetries = 5;
  const retryDelay = 5000;

  // Backend health check with retries
  log('  ğŸ¥ Checking backend health...');
  for (let i = 0; i < maxRetries; i++) {
    try {
      const backendHealth = await fetch(`${build.backendUrl}/health`, { timeout: 5000 });
      if (backendHealth.ok) {
        log('  âœ… Backend health check PASSED');
        break;
      }
    } catch (err) {
      if (i === maxRetries - 1) {
        log(`  âš ï¸  Backend health check failed after ${maxRetries} attempts: ${err.message}`);
      } else {
        log(`  â³ Backend not ready yet, retrying in ${retryDelay/1000}s... (${i+1}/${maxRetries})`);
        await new Promise(resolve => setTimeout(resolve, retryDelay));
      }
    }
  }

  // Frontend health check with retries
  log('  ğŸ¥ Checking frontend health...');
  for (let i = 0; i < maxRetries; i++) {
    try {
      const frontendHealth = await fetch(build.frontendUrl, { timeout: 5000 });
      if (frontendHealth.ok) {
        log('  âœ… Frontend health check PASSED');
        break;
      }
    } catch (err) {
      if (i === maxRetries - 1) {
        log(`  âš ï¸  Frontend health check failed after ${maxRetries} attempts: ${err.message}`);
      } else {
        log(`  â³ Frontend not ready yet, retrying in ${retryDelay/1000}s... (${i+1}/${maxRetries})`);
        await new Promise(resolve => setTimeout(resolve, retryDelay));
      }
    }
  }
}

// ========================================
// HELPER: Get Container Port
// ========================================
async function getContainerPort(buildId, serviceName, internalPort) {
  const containerName = `${buildId}_${serviceName}_1`;

  try {
    const { stdout } = await exec(
      `docker port ${containerName} ${internalPort} | cut -d: -f2`
    );
    return stdout.trim();
  } catch {
    // Try alternative method
    try {
      const { stdout } = await exec(
        `docker ps --filter name=${buildId} --filter name=${serviceName} --format "{{.Ports}}" | grep -oP '\\d+(?=->)' | head -1`
      );
      return stdout.trim();
    } catch {
      // Fallback to docker-compose ps
      const { stdout } = await exec(
        `docker-compose -p ${buildId} ps ${serviceName} | grep -oP '0.0.0.0:\\K\\d+' | head -1`
      );
      return stdout.trim();
    }
  }
}

// ========================================
// START SERVER
// ========================================
app.listen(PORT, '0.0.0.0', () => {
  console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   ğŸ¤– AI FACTORY - WF4 RUNNER           â•‘
â•‘   Port: ${PORT.toString().padEnd(28)} â•‘
â•‘   Status: READY âœ…                     â•‘
â•‘                                        â•‘
â•‘   Features:                            â•‘
â•‘   â€¢ Auto-fix missing dependencies      â•‘
â•‘   â€¢ Auto-fix TypeScript config         â•‘
â•‘   â€¢ Auto-create required directories   â•‘
â•‘   â€¢ Auto-commit & push to GitHub       â•‘
â•‘   â€¢ Docker build & deploy              â•‘
â•‘   â€¢ Health checks with retries         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  `);
});
